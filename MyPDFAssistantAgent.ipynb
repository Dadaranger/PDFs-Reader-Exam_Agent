{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzHjDu-VsGoa"
      },
      "outputs": [],
      "source": [
        "pip install streamlit google-generativeai chromadb langchain_google_genai  faiss-gpu PyPDF2 langchain python-dotenv pdfplumber\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJRL___Xu38q"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocadAYzVsNB5"
      },
      "outputs": [],
      "source": [
        "from dotenv import dotenv_values\n",
        "config = dotenv_values(\"/content/drive/MyDrive/Colab Notebooks/api.env\")\n",
        "print(config)\n",
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"]=\"YOUR GOOGLE API\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0-BXX8psNtx",
        "outputId": "f202755b-99ab-42e8-86be-b6a61710031d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading PDFs and processing text...\n",
            "Setup complete. You can now start asking questions.\n",
            "\n",
            "Ask a Question from the PDF Files (type 'exit' to quit): what is OPCON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'output_text': 'OPCON is the command authority that may be exercised by commanders at any echelon at or below the level of CCMD and may be delegated within the command.'}\n",
            "\n",
            "================================================================================\n",
            "Question:\n",
            "what is OPCON\n",
            "\n",
            "Answer:\n",
            "OPCON is the command authority that may be exercised by commanders at any\n",
            "echelon at or below the level of CCMD and may be delegated within the command.\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Ask a Question from the PDF Files (type 'exit' to quit): what is TACON\n",
            "{'output_text': 'TACON is an authority over assigned or attached forces or commands, or military capability or forces made available for tasking, that is limited to the detailed direction and control of movements and maneuvers within the operational area necessary to accomplish assigned missions or tasks assigned by the commander exercising OPCON or TACON of the attached force.'}\n",
            "\n",
            "================================================================================\n",
            "Question:\n",
            "what is TACON\n",
            "\n",
            "Answer:\n",
            "TACON is an authority over assigned or attached forces or commands, or military\n",
            "capability or forces made available for tasking, that is limited to the detailed\n",
            "direction and control of movements and maneuvers within the operational area\n",
            "necessary to accomplish assigned missions or tasks assigned by the commander\n",
            "exercising OPCON or TACON of the attached force.\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Ask a Question from the PDF Files (type 'exit' to quit): what is support\n",
            "{'output_text': 'Support is a command authority. A support relationship is established by a common superior commander between subordinate commanders when one organization should aid, protect, complement, or sustain another force. The support command relationship is used by SecDef to establish and prioritize support between and among CCDRs, and it is used by JFCs to establish support relationships between and among subordinate commanders.'}\n",
            "\n",
            "================================================================================\n",
            "Question:\n",
            "what is support\n",
            "\n",
            "Answer:\n",
            "Support is a command authority. A support relationship is established by a\n",
            "common superior commander between subordinate commanders when one organization\n",
            "should aid, protect, complement, or sustain another force. The support command\n",
            "relationship is used by SecDef to establish and prioritize support between and\n",
            "among CCDRs, and it is used by JFCs to establish support relationships between\n",
            "and among subordinate commanders.\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Ask a Question from the PDF Files (type 'exit' to quit): what is campaigning\n",
            "{'output_text': 'Campaigns and campaign planning follow the principles of joint operations while synchronizing efforts throughout the OE with all participants.'}\n",
            "\n",
            "================================================================================\n",
            "Question:\n",
            "what is campaigning\n",
            "\n",
            "Answer:\n",
            "Campaigns and campaign planning follow the principles of joint operations while\n",
            "synchronizing efforts throughout the OE with all participants.\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Ask a Question from the PDF Files (type 'exit' to quit): exit\n",
            "\n",
            "Exiting the Q&A session. Thank you!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "import google.generativeai as genai\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from dotenv import load_dotenv\n",
        "#from IPython.display import display, HTML\n",
        "import pdfplumber\n",
        "import textwrap\n",
        "# Configuration\n",
        "load_dotenv()\n",
        "os.getenv(\"GOOGLE_API_KEY\")\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "# Functions for PDF processing and text extraction\n",
        "def get_pdf_text(file_paths):\n",
        "    text = \"\"\n",
        "    for file_path in file_paths:\n",
        "        with pdfplumber.open(file_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text() if page.extract_text() else \" \"\n",
        "    return text\n",
        "\n",
        "def get_text_chunks(text):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)\n",
        "    return text_splitter.split_text(text)\n",
        "\n",
        "def get_vector_store(text_chunks):\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "    vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)\n",
        "    vector_store.save_local(\"faiss_index\")\n",
        "\n",
        "# Conversational chain setup\n",
        "def get_conversational_chain():\n",
        "    prompt_template = \"\"\"\n",
        "    Answer the question as detailed as possible from the provided context, make sure to provide all the details, if the answer is not in\n",
        "    provided context just say, \"answer is not available in the context\", don't provide the wrong answer\\n\\n\n",
        "    Context:\\n {context}?\\n\n",
        "    Question: \\n{question}\\n\n",
        "\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "    model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3)\n",
        "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "    return load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
        "\n",
        "# Question handling\n",
        "def user_input(user_question):\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "    new_db = FAISS.load_local(\"faiss_index\", embeddings,allow_dangerous_deserialization=True)\n",
        "    docs = new_db.similarity_search(user_question)\n",
        "    chain = get_conversational_chain()\n",
        "    response = chain({\"input_documents\": docs, \"question\": user_question}, return_only_outputs=True)\n",
        "    print(response)\n",
        "    return response\n",
        "\n",
        "# Main interaction loop in Jupyter\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Assuming all necessary functions like get_pdf_text, get_text_chunks, get_vector_store, and user_input are defined elsewhere\n",
        "\n",
        "def main():\n",
        "    load_dotenv()\n",
        "    pdf_path = [\n",
        "        '/content/drive/MyDrive/Colab Notebooks/1) JP 5-0 Joint Planning (01DEC20).pdf',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/2) JP 3-05 Joint Doctrine for Special Operations.pdf',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/3) JP 3-04 Information in Joint Operations.pdf',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/4) CJCSI 3110.05G MISO Supplement to Joint Strategic Campaign Plan.pdf',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/5) CJCSM 3105.01A Joint Risk Analysis Methodology.pdf',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/6) Defense Primer_What is Irregular Warfare.pdf',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/7) RAND_Intelligence Support for Operations in the Information Environment.pdf',\n",
        "        '/content/drive/MyDrive/Colab Notebooks/jp1.pdf'\n",
        "        # Add other PDFs as needed\n",
        "    ]\n",
        "    print(\"Loading PDFs and processing text...\")\n",
        "    raw_text = get_pdf_text(pdf_path)\n",
        "    text_chunks = get_text_chunks(raw_text)\n",
        "    get_vector_store(text_chunks)\n",
        "    print(\"Setup complete. You can now start asking questions.\")\n",
        "\n",
        "    while True:\n",
        "        user_question = input(\"\\nAsk a Question from the PDF Files (type 'exit' to quit): \").strip()\n",
        "        if user_question.lower() == 'exit':\n",
        "            print(\"\\nExiting the Q&A session. Thank you!\")\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            response = user_input(user_question)\n",
        "            # Using plain print instead of HTML display\n",
        "            wrapped_question = textwrap.fill(user_question, width=80)\n",
        "            wrapped_answer = textwrap.fill(response['output_text'],width=80)\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(f\"Question:\\n{wrapped_question}\\n\")\n",
        "            print(f\"Answer:\\n{wrapped_answer}\")\n",
        "            print(\"=\"*80+ \"\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError processing the question: {e}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}